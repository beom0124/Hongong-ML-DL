{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIpsvoT3XIKYiYiFf3q+9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beom0124/Hongong-ML-DL/blob/main/Logistic_Regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5kkjmaeC0oe",
        "outputId": "68fc7c39-9b6f-424f-e0a4-df6289ef709c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']\n",
            "[[0.  0.  0.6 0.  0.4 0.  0. ]\n",
            " [0.  0.  0.  0.  0.  1.  0. ]\n",
            " [0.  0.  0.2 0.8 0.  0.  0. ]\n",
            " [0.  0.  0.8 0.  0.2 0.  0. ]\n",
            " [0.  0.  0.8 0.  0.2 0.  0. ]]\n",
            "[['Roach' 'Perch' 'Perch' 'Perch' 'Perch']]\n",
            "0.9327731092436975\n",
            "0.925\n",
            "[[ -6.498   1.032   5.164  -2.729   3.339   0.327  -0.634]\n",
            " [-10.859   1.927   4.771  -2.398   2.978   7.841  -4.26 ]\n",
            " [ -4.335  -6.233   3.174   6.487   2.358   2.421  -3.872]\n",
            " [ -0.683   0.453   2.647  -1.187   3.265  -5.753   1.259]\n",
            " [ -6.397  -1.993   5.816  -0.11    3.503  -0.112  -0.707]]\n",
            "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
            " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
            " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
            " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
            " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.special import expit\n",
        "from scipy.special import softmax\n",
        "\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv')\n",
        "fish.head()\n",
        "\n",
        "print(pd.unique(fish['Species']))\n",
        "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()\n",
        "\n",
        "train_input, teat_input, train_target, test_target =train_test_split(fish_input, fish_target,random_state = 42)\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(teat_input)\n",
        "\n",
        "kn = KNeighborsClassifier()\n",
        "kn.fit(train_scaled, train_target)\n",
        "\n",
        "proba = kn.predict_proba(test_scaled[:5])\n",
        "print(np.round(proba, decimals=4))\n",
        "\n",
        "distances, indexes = kn.kneighbors(test_scaled[3:4])\n",
        "print(train_target[indexes])\n",
        "\n",
        "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')\n",
        "train_bream_smelt = train_scaled[bream_smelt_indexes]\n",
        "target_bream_smelt = train_target[bream_smelt_indexes]\n",
        "\n",
        "# lr = LogisticRegression() 로직스틱 회귀를 통한 이진분류\n",
        "# lr.fit(train_bream_smelt, target_bream_smelt)\n",
        "\n",
        "# print(lr.predict(train_bream_smelt[:5]))\n",
        "\n",
        "# print(lr.predict_proba(train_bream_smelt[:5]))\n",
        "\n",
        "# decision = lr.decision_function(train_bream_smelt[:5])\n",
        "# print(decision) #Logistic Regression이 학습한 계수\n",
        "# print(expit(decision))\n",
        "\n",
        "\n",
        "lr = LogisticRegression(C=20, max_iter=1000) # C는 규제를 제어하는 매개변수(작을수록 크게 규제), iter는 반복 횟수\n",
        "lr.fit(train_scaled, train_target)\n",
        "print(lr.score(train_scaled, train_target))\n",
        "print(lr.score(test_scaled, test_target))\n",
        "\n",
        "# proba = lr.predict_proba(test_scaled[:5])\n",
        "# print(np.round(proba, decimals = 3))\n",
        "\n",
        "decision = lr.decision_function(test_scaled[:5])\n",
        "print(np.round(decision, decimals=3))\n",
        "\n",
        "proba = softmax(decision, axis =1)\n",
        "print(np.round(proba, decimals = 3))"
      ]
    }
  ]
}